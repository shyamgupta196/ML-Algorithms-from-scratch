{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d2fb88e0",
   "metadata": {
    "papermill": {
     "duration": 0.011895,
     "end_time": "2024-05-25T05:04:48.189930",
     "exception": false,
     "start_time": "2024-05-25T05:04:48.178035",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ea3f32a",
   "metadata": {
    "papermill": {
     "duration": 0.010945,
     "end_time": "2024-05-25T05:04:48.212258",
     "exception": false,
     "start_time": "2024-05-25T05:04:48.201313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ce498c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:04:48.236237Z",
     "iopub.status.busy": "2024-05-25T05:04:48.235886Z",
     "iopub.status.idle": "2024-05-25T05:06:21.030384Z",
     "shell.execute_reply": "2024-05-25T05:06:21.029305Z"
    },
    "papermill": {
     "duration": 92.809411,
     "end_time": "2024-05-25T05:06:21.032844",
     "exception": false,
     "start_time": "2024-05-25T05:04:48.223433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/dependencies-imc/pycolmap/pycolmap-0.4.0-cp310-cp310-manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: pycolmap\r\n",
      "Successfully installed pycolmap-0.4.0\r\n",
      "Processing /kaggle/input/dependencies-imc/safetensors/safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: safetensors\r\n",
      "  Attempting uninstall: safetensors\r\n",
      "    Found existing installation: safetensors 0.4.3\r\n",
      "    Uninstalling safetensors-0.4.3:\r\n",
      "      Successfully uninstalled safetensors-0.4.3\r\n",
      "Successfully installed safetensors-0.4.1\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\r\n",
      "Installing collected packages: lightglue\r\n",
      "Successfully installed lightglue-0.0\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --no-deps /kaggle/input/dependencies-imc/pycolmap/pycolmap-0.4.0-cp310-cp310-manylinux2014_x86_64.whl\n",
    "!python -m pip install --no-deps /kaggle/input/dependencies-imc/safetensors/safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!python -m pip install --no-index --find-links=/kaggle/input/dependencies-imc/transformers/ transformers > /dev/null\n",
    "!python -m pip install  --no-deps /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\n",
    "\n",
    "# dkm\n",
    "!python -m pip install --no-index --find-links=/kaggle/input/dkm-dependencies/packages einops > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b936309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:21.060807Z",
     "iopub.status.busy": "2024-05-25T05:06:21.060443Z",
     "iopub.status.idle": "2024-05-25T05:06:32.618966Z",
     "shell.execute_reply": "2024-05-25T05:06:32.617708Z"
    },
    "papermill": {
     "duration": 11.575725,
     "end_time": "2024-05-25T05:06:32.621349",
     "exception": false,
     "start_time": "2024-05-25T05:06:21.045624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lightglue models\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
    "!cp /kaggle/input/aliked/pytorch/aliked-n16/1/* /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/* /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth\n",
    "!cp /kaggle/input/pytorch-lightglue-models/* /root/.cache/torch/hub/checkpoints/\n",
    "\n",
    "# dkm model\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
    "!cp /kaggle/input/dkm-dependencies/DKMv3_outdoor.pth /root/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d988cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:32.647471Z",
     "iopub.status.busy": "2024-05-25T05:06:32.647144Z",
     "iopub.status.idle": "2024-05-25T05:06:32.653171Z",
     "shell.execute_reply": "2024-05-25T05:06:32.652182Z"
    },
    "papermill": {
     "duration": 0.021228,
     "end_time": "2024-05-25T05:06:32.655129",
     "exception": false,
     "start_time": "2024-05-25T05:06:32.633901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6acae5ee",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:32.682121Z",
     "iopub.status.busy": "2024-05-25T05:06:32.681408Z",
     "iopub.status.idle": "2024-05-25T05:06:42.107545Z",
     "shell.execute_reply": "2024-05-25T05:06:42.106546Z"
    },
    "papermill": {
     "duration": 9.442781,
     "end_time": "2024-05-25T05:06:42.109928",
     "exception": false,
     "start_time": "2024-05-25T05:06:32.667147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General utilities\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from fastprogress import progress_bar\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "# CV/ML\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from PIL import Image\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# 3D reconstruction\n",
    "import pycolmap\n",
    "\n",
    "import glob\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# dkm\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/dkm-dependencies/DKM/')\n",
    "from dkm.utils.utils import tensor_to_pil, get_tuple_transform_ops\n",
    "from dkm import DKMv3_outdoor\n",
    "\n",
    "# LoFTR\n",
    "from kornia.feature import LoFTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e044f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.138351Z",
     "iopub.status.busy": "2024-05-25T05:06:42.138000Z",
     "iopub.status.idle": "2024-05-25T05:06:42.147241Z",
     "shell.execute_reply": "2024-05-25T05:06:42.146359Z"
    },
    "papermill": {
     "duration": 0.025919,
     "end_time": "2024-05-25T05:06:42.149182",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.123263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightglue import match_pair\n",
    "from lightglue import ALIKED, SuperPoint, DoGHardNet, LightGlue\n",
    "from lightglue.utils import load_image, rbd\n",
    "from kornia.feature import LoFTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c28fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.179205Z",
     "iopub.status.busy": "2024-05-25T05:06:42.178859Z",
     "iopub.status.idle": "2024-05-25T05:06:42.183950Z",
     "shell.execute_reply": "2024-05-25T05:06:42.182982Z"
    },
    "papermill": {
     "duration": 0.022397,
     "end_time": "2024-05-25T05:06:42.186443",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.164046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kornia version 0.7.2\n",
      "Pycolmap version 0.4.0\n"
     ]
    }
   ],
   "source": [
    "print('Kornia version', K.__version__)\n",
    "print('Pycolmap version', pycolmap.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dc1744",
   "metadata": {
    "papermill": {
     "duration": 0.01187,
     "end_time": "2024-05-25T05:06:42.210482",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.198612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc9e5f6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.236282Z",
     "iopub.status.busy": "2024-05-25T05:06:42.235950Z",
     "iopub.status.idle": "2024-05-25T05:06:42.244141Z",
     "shell.execute_reply": "2024-05-25T05:06:42.243299Z"
    },
    "papermill": {
     "duration": 0.023571,
     "end_time": "2024-05-25T05:06:42.246175",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.222604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    use_aliked_lightglue = True\n",
    "    use_doghardnet_lightglue = False\n",
    "    use_superpoint_lightglue = True\n",
    "    use_loftr = True\n",
    "    use_dkm = False\n",
    "    use_superglue = False\n",
    "    \n",
    "    params_aliked_lightglue = {\n",
    "        \"num_features\" : 8192,\n",
    "        \"detection_threshold\" : 0.001,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : 1024,\n",
    "    }\n",
    "    \n",
    "    params_doghardnet_lightglue = {\n",
    "        \"num_features\" : 8192,\n",
    "        \"detection_threshold\" : 0.001,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : 1024,\n",
    "    }\n",
    "    \n",
    "    params_superpoint_lightglue = {\n",
    "        \"num_features\" : 4096,\n",
    "        \"detection_threshold\" : 0.005,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : 1024,\n",
    "    }\n",
    "    \n",
    "    params_loftr = {\n",
    "        \"resize_small_edge_to\" : 750,\n",
    "        \"min_matches\" : 15,\n",
    "    }\n",
    "    \n",
    "    params_dkm = {\n",
    "        \"num_features\" : 2048,\n",
    "        \"detection_threshold\" : 0.4,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : (540, 720),    \n",
    "    }\n",
    "    \n",
    "    params_sg = {\n",
    "        \"sg_config\" : \n",
    "        {\n",
    "            \"superpoint\": {\n",
    "                \"nms_radius\": 4, \n",
    "                \"keypoint_threshold\": 0.0001,\n",
    "                \"max_keypoints\": 4096\n",
    "            },\n",
    "            \"superglue\": {\n",
    "                \"weights\": \"outdoor\",\n",
    "                \"sinkhorn_iterations\": 10,\n",
    "                \"match_threshold\": 0.2,\n",
    "            },\n",
    "        },\n",
    "        \"resize_to\": 1240,\n",
    "        \"min_matches\": 15,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c826c899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.271891Z",
     "iopub.status.busy": "2024-05-25T05:06:42.271609Z",
     "iopub.status.idle": "2024-05-25T05:06:42.275571Z",
     "shell.execute_reply": "2024-05-25T05:06:42.274690Z"
    },
    "papermill": {
     "duration": 0.019119,
     "end_time": "2024-05-25T05:06:42.277447",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.258328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af690a",
   "metadata": {
    "papermill": {
     "duration": 0.01203,
     "end_time": "2024-05-25T05:06:42.301842",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.289812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# COLMAP utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51fd4a4f",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.327985Z",
     "iopub.status.busy": "2024-05-25T05:06:42.327675Z",
     "iopub.status.idle": "2024-05-25T05:06:42.356199Z",
     "shell.execute_reply": "2024-05-25T05:06:42.355262Z"
    },
    "papermill": {
     "duration": 0.044141,
     "end_time": "2024-05-25T05:06:42.358123",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.313982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code to manipulate a colmap database.\n",
    "# Forked from https://github.com/colmap/colmap/blob/dev/scripts/python/database.py\n",
    "\n",
    "# Copyright (c) 2018, ETH Zurich and UNC Chapel Hill.\n",
    "# All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#     * Redistributions of source code must retain the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer.\n",
    "#\n",
    "#     * Redistributions in binary form must reproduce the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer in the\n",
    "#       documentation and/or other materials provided with the distribution.\n",
    "#\n",
    "#     * Neither the name of ETH Zurich and UNC Chapel Hill nor the names of\n",
    "#       its contributors may be used to endorse or promote products derived\n",
    "#       from this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE\n",
    "# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "# POSSIBILITY OF SUCH DAMAGE.\n",
    "#\n",
    "# Author: Johannes L. Schoenberger (jsch-at-demuc-dot-de)\n",
    "\n",
    "# This script is based on an original implementation by True Price.\n",
    "\n",
    "import sys\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "IS_PYTHON3 = sys.version_info[0] >= 3\n",
    "\n",
    "MAX_IMAGE_ID = 2**31 - 1\n",
    "\n",
    "CREATE_CAMERAS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS cameras (\n",
    "    camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    model INTEGER NOT NULL,\n",
    "    width INTEGER NOT NULL,\n",
    "    height INTEGER NOT NULL,\n",
    "    params BLOB,\n",
    "    prior_focal_length INTEGER NOT NULL)\"\"\"\n",
    "\n",
    "CREATE_DESCRIPTORS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS descriptors (\n",
    "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)\"\"\"\n",
    "\n",
    "CREATE_IMAGES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS images (\n",
    "    image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    name TEXT NOT NULL UNIQUE,\n",
    "    camera_id INTEGER NOT NULL,\n",
    "    prior_qw REAL,\n",
    "    prior_qx REAL,\n",
    "    prior_qy REAL,\n",
    "    prior_qz REAL,\n",
    "    prior_tx REAL,\n",
    "    prior_ty REAL,\n",
    "    prior_tz REAL,\n",
    "    CONSTRAINT image_id_check CHECK(image_id >= 0 and image_id < {}),\n",
    "    FOREIGN KEY(camera_id) REFERENCES cameras(camera_id))\n",
    "\"\"\".format(MAX_IMAGE_ID)\n",
    "\n",
    "CREATE_TWO_VIEW_GEOMETRIES_TABLE = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS two_view_geometries (\n",
    "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    config INTEGER NOT NULL,\n",
    "    F BLOB,\n",
    "    E BLOB,\n",
    "    H BLOB)\n",
    "\"\"\"\n",
    "\n",
    "CREATE_KEYPOINTS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS keypoints (\n",
    "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)\n",
    "\"\"\"\n",
    "\n",
    "CREATE_MATCHES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS matches (\n",
    "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB)\"\"\"\n",
    "\n",
    "CREATE_NAME_INDEX = \\\n",
    "    \"CREATE UNIQUE INDEX IF NOT EXISTS index_name ON images(name)\"\n",
    "\n",
    "CREATE_ALL = \"; \".join([\n",
    "    CREATE_CAMERAS_TABLE,\n",
    "    CREATE_IMAGES_TABLE,\n",
    "    CREATE_KEYPOINTS_TABLE,\n",
    "    CREATE_DESCRIPTORS_TABLE,\n",
    "    CREATE_MATCHES_TABLE,\n",
    "    CREATE_TWO_VIEW_GEOMETRIES_TABLE,\n",
    "    CREATE_NAME_INDEX\n",
    "])\n",
    "\n",
    "\n",
    "def image_ids_to_pair_id(image_id1, image_id2):\n",
    "    if image_id1 > image_id2:\n",
    "        image_id1, image_id2 = image_id2, image_id1\n",
    "    return image_id1 * MAX_IMAGE_ID + image_id2\n",
    "\n",
    "\n",
    "def pair_id_to_image_ids(pair_id):\n",
    "    image_id2 = pair_id % MAX_IMAGE_ID\n",
    "    image_id1 = (pair_id - image_id2) / MAX_IMAGE_ID\n",
    "    return image_id1, image_id2\n",
    "\n",
    "\n",
    "def array_to_blob(array):\n",
    "    if IS_PYTHON3:\n",
    "        return array.tostring()\n",
    "    else:\n",
    "        return np.getbuffer(array)\n",
    "\n",
    "\n",
    "def blob_to_array(blob, dtype, shape=(-1,)):\n",
    "    if IS_PYTHON3:\n",
    "        return np.fromstring(blob, dtype=dtype).reshape(*shape)\n",
    "    else:\n",
    "        return np.frombuffer(blob, dtype=dtype).reshape(*shape)\n",
    "\n",
    "\n",
    "class COLMAPDatabase(sqlite3.Connection):\n",
    "\n",
    "    @staticmethod\n",
    "    def connect(database_path):\n",
    "        return sqlite3.connect(database_path, factory=COLMAPDatabase)\n",
    "\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(COLMAPDatabase, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.create_tables = lambda: self.executescript(CREATE_ALL)\n",
    "        self.create_cameras_table = \\\n",
    "            lambda: self.executescript(CREATE_CAMERAS_TABLE)\n",
    "        self.create_descriptors_table = \\\n",
    "            lambda: self.executescript(CREATE_DESCRIPTORS_TABLE)\n",
    "        self.create_images_table = \\\n",
    "            lambda: self.executescript(CREATE_IMAGES_TABLE)\n",
    "        self.create_two_view_geometries_table = \\\n",
    "            lambda: self.executescript(CREATE_TWO_VIEW_GEOMETRIES_TABLE)\n",
    "        self.create_keypoints_table = \\\n",
    "            lambda: self.executescript(CREATE_KEYPOINTS_TABLE)\n",
    "        self.create_matches_table = \\\n",
    "            lambda: self.executescript(CREATE_MATCHES_TABLE)\n",
    "        self.create_name_index = lambda: self.executescript(CREATE_NAME_INDEX)\n",
    "\n",
    "    def add_camera(self, model, width, height, params,\n",
    "                   prior_focal_length=False, camera_id=None):\n",
    "        params = np.asarray(params, np.float64)\n",
    "        cursor = self.execute(\n",
    "            \"INSERT INTO cameras VALUES (?, ?, ?, ?, ?, ?)\",\n",
    "            (camera_id, model, width, height, array_to_blob(params),\n",
    "             prior_focal_length))\n",
    "        return cursor.lastrowid\n",
    "\n",
    "    def add_image(self, name, camera_id,\n",
    "                  prior_q=np.zeros(4), prior_t=np.zeros(3), image_id=None):\n",
    "        cursor = self.execute(\n",
    "            \"INSERT INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "            (image_id, name, camera_id, prior_q[0], prior_q[1], prior_q[2],\n",
    "             prior_q[3], prior_t[0], prior_t[1], prior_t[2]))\n",
    "        return cursor.lastrowid\n",
    "\n",
    "    def add_keypoints(self, image_id, keypoints):\n",
    "        assert(len(keypoints.shape) == 2)\n",
    "        assert(keypoints.shape[1] in [2, 4, 6])\n",
    "\n",
    "        keypoints = np.asarray(keypoints, np.float32)\n",
    "        self.execute(\n",
    "            \"INSERT INTO keypoints VALUES (?, ?, ?, ?)\",\n",
    "            (image_id,) + keypoints.shape + (array_to_blob(keypoints),))\n",
    "\n",
    "    def add_descriptors(self, image_id, descriptors):\n",
    "        descriptors = np.ascontiguousarray(descriptors, np.uint8)\n",
    "        self.execute(\n",
    "            \"INSERT INTO descriptors VALUES (?, ?, ?, ?)\",\n",
    "            (image_id,) + descriptors.shape + (array_to_blob(descriptors),))\n",
    "\n",
    "    def add_matches(self, image_id1, image_id2, matches):\n",
    "        assert(len(matches.shape) == 2)\n",
    "        assert(matches.shape[1] == 2)\n",
    "\n",
    "        if image_id1 > image_id2:\n",
    "            matches = matches[:,::-1]\n",
    "\n",
    "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
    "        matches = np.asarray(matches, np.uint32)\n",
    "        self.execute(\n",
    "            \"INSERT INTO matches VALUES (?, ?, ?, ?)\",\n",
    "            (pair_id,) + matches.shape + (array_to_blob(matches),))\n",
    "\n",
    "    def add_two_view_geometry(self, image_id1, image_id2, matches,\n",
    "                              F=np.eye(3), E=np.eye(3), H=np.eye(3), config=2):\n",
    "        assert(len(matches.shape) == 2)\n",
    "        assert(matches.shape[1] == 2)\n",
    "\n",
    "        if image_id1 > image_id2:\n",
    "            matches = matches[:,::-1]\n",
    "\n",
    "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
    "        matches = np.asarray(matches, np.uint32)\n",
    "        F = np.asarray(F, dtype=np.float64)\n",
    "        E = np.asarray(E, dtype=np.float64)\n",
    "        H = np.asarray(H, dtype=np.float64)\n",
    "        self.execute(\n",
    "            \"INSERT INTO two_view_geometries VALUES (?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "            (pair_id,) + matches.shape + (array_to_blob(matches), config,\n",
    "             array_to_blob(F), array_to_blob(E), array_to_blob(H)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45a60f",
   "metadata": {
    "papermill": {
     "duration": 0.01213,
     "end_time": "2024-05-25T05:06:42.383042",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.370912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# h5 to colmap db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8f3c4e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.409197Z",
     "iopub.status.busy": "2024-05-25T05:06:42.408855Z",
     "iopub.status.idle": "2024-05-25T05:06:42.429701Z",
     "shell.execute_reply": "2024-05-25T05:06:42.428829Z"
    },
    "papermill": {
     "duration": 0.036162,
     "end_time": "2024-05-25T05:06:42.431545",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.395383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code to interface DISK with Colmap.\n",
    "# Forked from https://github.com/cvlab-epfl/disk/blob/37f1f7e971cea3055bb5ccfc4cf28bfd643fa339/colmap/h5_to_db.py\n",
    "\n",
    "#  Copyright [2020] [Micha≈Ç Tyszkiewicz, Pascal Fua, Eduard Trulls]\n",
    "#\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "#\n",
    "#       http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#   Unless required by applicable law or agreed to in writing, software\n",
    "#   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#   See the License for the specific language governing permissions and\n",
    "#   limitations under the License.\n",
    "\n",
    "import os, argparse, h5py, warnings\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "\n",
    "def get_focal(image_path, err_on_default=False):\n",
    "    image         = Image.open(image_path)\n",
    "    max_size      = max(image.size)\n",
    "\n",
    "    exif = image.getexif()\n",
    "    focal = None\n",
    "    if exif is not None:\n",
    "        focal_35mm = None\n",
    "        # https://github.com/colmap/colmap/blob/d3a29e203ab69e91eda938d6e56e1c7339d62a99/src/util/bitmap.cc#L299\n",
    "        for tag, value in exif.items():\n",
    "            focal_35mm = None\n",
    "            if ExifTags.TAGS.get(tag, None) == 'FocalLengthIn35mmFilm':\n",
    "                focal_35mm = float(value)\n",
    "                break\n",
    "\n",
    "        if focal_35mm is not None:\n",
    "            focal = focal_35mm / 35. * max_size\n",
    "    \n",
    "    if focal is None:\n",
    "        if err_on_default:\n",
    "            raise RuntimeError(\"Failed to find focal length\")\n",
    "\n",
    "        # failed to find it in exif, use prior\n",
    "        FOCAL_PRIOR = 1.2\n",
    "        focal = FOCAL_PRIOR * max_size\n",
    "\n",
    "    return focal\n",
    "\n",
    "def create_camera(db, image_path, camera_model):\n",
    "    image         = Image.open(image_path)\n",
    "    width, height = image.size\n",
    "\n",
    "    focal = get_focal(image_path)\n",
    "\n",
    "    if camera_model == 'simple-pinhole':\n",
    "        model = 0 # simple pinhole\n",
    "        param_arr = np.array([focal, width / 2, height / 2])\n",
    "    if camera_model == 'pinhole':\n",
    "        model = 1 # pinhole\n",
    "        param_arr = np.array([focal, focal, width / 2, height / 2])\n",
    "    elif camera_model == 'simple-radial':\n",
    "        model = 2 # simple radial\n",
    "        param_arr = np.array([focal, width / 2, height / 2, 0.1])\n",
    "    elif camera_model == 'opencv':\n",
    "        model = 4 # opencv\n",
    "        param_arr = np.array([focal, focal, width / 2, height / 2, 0., 0., 0., 0.])\n",
    "         \n",
    "    return db.add_camera(model, width, height, param_arr)\n",
    "\n",
    "\n",
    "def add_keypoints(db, h5_path, image_path, img_ext, camera_model, single_camera = True):\n",
    "    keypoint_f = h5py.File(os.path.join(h5_path, 'keypoints.h5'), 'r')\n",
    "\n",
    "    camera_id = None\n",
    "    fname_to_id = {}\n",
    "    for filename in tqdm(list(keypoint_f.keys())):\n",
    "        keypoints = keypoint_f[filename][()]\n",
    "\n",
    "        fname_with_ext = filename# + img_ext\n",
    "        path = os.path.join(image_path, fname_with_ext)\n",
    "        if not os.path.isfile(path):\n",
    "            raise IOError(f'Invalid image path {path}')\n",
    "\n",
    "        if camera_id is None or not single_camera:\n",
    "            camera_id = create_camera(db, path, camera_model)\n",
    "        image_id = db.add_image(fname_with_ext, camera_id)\n",
    "        fname_to_id[filename] = image_id\n",
    "\n",
    "        db.add_keypoints(image_id, keypoints)\n",
    "\n",
    "    return fname_to_id\n",
    "\n",
    "def add_matches(db, h5_path, fname_to_id):\n",
    "    match_file = h5py.File(os.path.join(h5_path, 'matches.h5'), 'r')\n",
    "    \n",
    "    added = set()\n",
    "    n_keys = len(match_file.keys())\n",
    "    n_total = (n_keys * (n_keys - 1)) // 2\n",
    "\n",
    "    with tqdm(total=n_total) as pbar:\n",
    "        for key_1 in match_file.keys():\n",
    "            group = match_file[key_1]\n",
    "            for key_2 in group.keys():\n",
    "                id_1 = fname_to_id[key_1]\n",
    "                id_2 = fname_to_id[key_2]\n",
    "\n",
    "                pair_id = image_ids_to_pair_id(id_1, id_2)\n",
    "                if pair_id in added:\n",
    "                    warnings.warn(f'Pair {pair_id} ({id_1}, {id_2}) already added!')\n",
    "                    continue\n",
    "            \n",
    "                matches = group[key_2][()]\n",
    "                db.add_matches(id_1, id_2, matches)\n",
    "\n",
    "                added.add(pair_id)\n",
    "\n",
    "                pbar.update(1)\n",
    "                \n",
    "def import_into_colmap(img_dir,\n",
    "                       feature_dir ='.featureout',\n",
    "                       database_path = 'colmap.db',\n",
    "                       img_ext='.jpg'):\n",
    "    db = COLMAPDatabase.connect(database_path)\n",
    "    db.create_tables()\n",
    "    single_camera = False\n",
    "    fname_to_id = add_keypoints(db, feature_dir, img_dir, img_ext, 'simple-radial', single_camera)\n",
    "    add_matches(\n",
    "        db,\n",
    "        feature_dir,\n",
    "        fname_to_id,\n",
    "    )\n",
    "\n",
    "    db.commit()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a60a3",
   "metadata": {
    "papermill": {
     "duration": 0.012427,
     "end_time": "2024-05-25T05:06:42.456600",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.444173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04ec5145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.483841Z",
     "iopub.status.busy": "2024-05-25T05:06:42.483506Z",
     "iopub.status.idle": "2024-05-25T05:06:42.501104Z",
     "shell.execute_reply": "2024-05-25T05:06:42.500247Z"
    },
    "papermill": {
     "duration": 0.033697,
     "end_time": "2024-05-25T05:06:42.503022",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.469325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will use ViT global descriptor to get matching shortlists.\n",
    "def get_global_desc(fnames, model,\n",
    "                    device =  device):\n",
    "    model = model.eval()\n",
    "    model= model.to(device)\n",
    "    config = resolve_data_config({}, model=model)\n",
    "    transform = create_transform(**config)\n",
    "    global_descs_convnext=[]\n",
    "    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n",
    "        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n",
    "        img = Image.open(img_fname_full).convert('RGB')\n",
    "        timg = transform(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            desc = model.forward_features(timg.to(device)).mean(dim=(-1,2))#\n",
    "            #print (desc.shape)\n",
    "            desc = desc.view(1, -1)\n",
    "            desc_norm = F.normalize(desc, dim=1, p=2)\n",
    "        #print (desc_norm)\n",
    "        global_descs_convnext.append(desc_norm.detach().cpu())\n",
    "    global_descs_all = torch.cat(global_descs_convnext, dim=0)\n",
    "    return global_descs_all.to(torch.float32)\n",
    "\n",
    "def convert_1d_to_2d(idx, num_images):\n",
    "    idx1 = idx // num_images\n",
    "    idx2 = idx % num_images\n",
    "    return (idx1, idx2)\n",
    "\n",
    "def get_pairs_from_distancematrix(mat):\n",
    "    pairs = [ convert_1d_to_2d(idx, mat.shape[0]) for idx in np.argsort(mat.flatten())]\n",
    "    pairs = [ pair for pair in pairs if pair[0] < pair[1] ]\n",
    "    return pairs\n",
    "\n",
    "def get_img_pairs_exhaustive(img_fnames, model, device):\n",
    "    #index_pairs = []\n",
    "    #for i in range(len(img_fnames)):\n",
    "    #    for j in range(i+1, len(img_fnames)):\n",
    "    #        index_pairs.append((i,j))\n",
    "    #return index_pairs\n",
    "    descs = get_global_desc(img_fnames, model, device=device)\n",
    "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
    "    matching_list = get_pairs_from_distancematrix(dm)\n",
    "    return matching_list\n",
    "\n",
    "\n",
    "def get_image_pairs_shortlist(fnames,\n",
    "                              sim_th = 0.5, # should be strict\n",
    "                              min_pairs = 40,\n",
    "                              exhaustive_if_less = 40,\n",
    "                              device=device):\n",
    "    num_imgs = len(fnames)\n",
    "\n",
    "    model = timm.create_model('tf_efficientnet_l2',\n",
    "                              checkpoint_path='/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-l2-ns-475/1/tf_efficientnet_l2_ns_475-bebbd00a.pth')\n",
    "    model.eval()\n",
    "    descs = get_global_desc(fnames, model, device=device)\n",
    "\n",
    "    if num_imgs <= exhaustive_if_less:\n",
    "        return get_img_pairs_exhaustive(fnames, model, device)\n",
    "    \n",
    "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
    "    # removing half\n",
    "    mask = dm <= sim_th\n",
    "    total = 0\n",
    "    matching_list = []\n",
    "    ar = np.arange(num_imgs)\n",
    "    already_there_set = []\n",
    "    for st_idx in range(num_imgs-1):\n",
    "        mask_idx = mask[st_idx]\n",
    "        to_match = ar[mask_idx]\n",
    "        if len(to_match) < min_pairs:\n",
    "            to_match = np.argsort(dm[st_idx])[:min_pairs]  \n",
    "        for idx in to_match:\n",
    "            if st_idx == idx:\n",
    "                continue\n",
    "            if dm[st_idx, idx] < 1000:\n",
    "                matching_list.append(tuple(sorted((st_idx, idx.item()))))\n",
    "                total+=1\n",
    "    matching_list = sorted(list(set(matching_list)))\n",
    "    return matching_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d03bd",
   "metadata": {
    "papermill": {
     "duration": 0.017861,
     "end_time": "2024-05-25T05:06:42.533129",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.515268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keypoints: LightGlue series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0005b360",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.569154Z",
     "iopub.status.busy": "2024-05-25T05:06:42.568790Z",
     "iopub.status.idle": "2024-05-25T05:06:42.593107Z",
     "shell.execute_reply": "2024-05-25T05:06:42.592173Z"
    },
    "papermill": {
     "duration": 0.045521,
     "end_time": "2024-05-25T05:06:42.595117",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.549596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_torch_image(fname, device=torch.device('cpu')):\n",
    "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
    "    return img\n",
    "\n",
    "def detect_common(img_fnames,\n",
    "                  model_name,\n",
    "                  feature_dir = '.featureout',\n",
    "                  num_features = 4096,\n",
    "                  resize_to = 1024,\n",
    "                  detection_threshold = 0.01,\n",
    "                  device=torch.device('cpu')):\n",
    "    \n",
    "    dict_model = {\n",
    "        \"aliked\" : ALIKED,\n",
    "        \"superpoint\" : SuperPoint,\n",
    "        \"doghardnet\" : DoGHardNet,\n",
    "    }\n",
    "    extractor_class = dict_model[model_name]\n",
    "    \n",
    "    dtype = torch.float32 # ALIKED has issues with float16\n",
    "    extractor = extractor_class(\n",
    "        max_num_keypoints=num_features, detection_threshold=detection_threshold, resize=resize_to\n",
    "    ).eval().to(device, dtype)\n",
    "    if not os.path.isdir(feature_dir):\n",
    "        os.makedirs(feature_dir)\n",
    "    with h5py.File(f'{feature_dir}/keypoints_{model_name}.h5', mode='w') as f_kp, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors_{model_name}.h5', mode='w') as f_desc:\n",
    "        for img_path in tqdm(img_fnames):\n",
    "            img_fname = img_path.split('/')[-1]\n",
    "            key = img_fname\n",
    "            with torch.inference_mode():\n",
    "                image0 = load_torch_image(img_path, device=device).to(dtype)\n",
    "                feats0 = extractor.extract(image0)  # auto-resize the image, disable with resize=None\n",
    "                kpts = feats0['keypoints'].reshape(-1, 2).detach().cpu().numpy()\n",
    "                descs = feats0['descriptors'].reshape(len(kpts), -1).detach().cpu().numpy()\n",
    "                f_kp[key] = kpts\n",
    "                f_desc[key] = descs\n",
    "                print(f\"{model_name} > kpts.shape={kpts.shape}, descs.shape={descs.shape}\")\n",
    "    return\n",
    "\n",
    "def match_with_lightglue_common(img_fnames, model_name,\n",
    "                   index_pairs, file_keypoints,\n",
    "                   feature_dir = '.featureout',\n",
    "                   device=torch.device('cpu'),\n",
    "                   min_matches=15,verbose=True):\n",
    "    lg_matcher = KF.LightGlueMatcher(model_name, {\"width_confidence\": -1,\n",
    "                                                \"depth_confidence\": -1,\n",
    "                                                 \"mp\": True if 'cuda' in str(device) else False}).eval().to(device)\n",
    "    \n",
    "    cnt_pairs = 0\n",
    "    with h5py.File(f'{feature_dir}/keypoints_{model_name}.h5', mode='r') as f_kp, \\\n",
    "        h5py.File(f'{feature_dir}/descriptors_{model_name}.h5', mode='r') as f_desc, \\\n",
    "        h5py.File(file_keypoints, mode='w') as f_match:\n",
    "        for pair_idx in tqdm(index_pairs):\n",
    "            idx1, idx2 = pair_idx\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "            \n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "            kp1 = torch.from_numpy(f_kp[key1][...]).to(device)\n",
    "            kp2 = torch.from_numpy(f_kp[key2][...]).to(device)\n",
    "            desc1 = torch.from_numpy(f_desc[key1][...]).to(device)\n",
    "            desc2 = torch.from_numpy(f_desc[key2][...]).to(device)\n",
    "            with torch.inference_mode():\n",
    "                dists, idxs = lg_matcher(desc1,\n",
    "                                         desc2,\n",
    "                                         KF.laf_from_center_scale_ori(kp1[None]),\n",
    "                                         KF.laf_from_center_scale_ori(kp2[None]))\n",
    "            if len(idxs)  == 0:\n",
    "                continue\n",
    "            n_matches = len(idxs)\n",
    "            kp1 = kp1[idxs[:,0], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n",
    "            kp2 = kp2[idxs[:,1], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n",
    "            group  = f_match.require_group(key1)\n",
    "            if n_matches >= min_matches:\n",
    "                group.create_dataset(key2, data=np.concatenate([kp1, kp2], axis=1))\n",
    "                cnt_pairs+=1\n",
    "                print (f'{key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair({model_name}+lightglue)')            \n",
    "            else:\n",
    "                print (f'{key1}-{key2}: {n_matches} matches --> skipped')            \n",
    "    return\n",
    "\n",
    "def detect_lightglue_common(\n",
    "    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints,\n",
    "    resize_to=1024,\n",
    "    detection_threshold=0.01, \n",
    "    num_features=4096, \n",
    "    min_matches=15,\n",
    "):\n",
    "    t=time()\n",
    "    detect_common(\n",
    "        img_fnames, model_name, feature_dir, \n",
    "        resize_to=resize_to,\n",
    "        num_features=num_features, \n",
    "        detection_threshold=detection_threshold, \n",
    "        device=device\n",
    "    )\n",
    "    gc.collect()\n",
    "    match_with_lightglue_common(\n",
    "        img_fnames, model_name, index_pairs, file_keypoints,\n",
    "        feature_dir=feature_dir,\n",
    "        min_matches=min_matches,\n",
    "        device=device\n",
    "    )\n",
    "    t=time() -t \n",
    "    print(f'Features matched in  {t:.4f} sec ({model_name}+LightGlue)')\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7ad509",
   "metadata": {
    "papermill": {
     "duration": 0.012672,
     "end_time": "2024-05-25T05:06:42.621408",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.608736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keypoints: SuperGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5a7e168",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.648925Z",
     "iopub.status.busy": "2024-05-25T05:06:42.648548Z",
     "iopub.status.idle": "2024-05-25T05:06:42.719743Z",
     "shell.execute_reply": "2024-05-25T05:06:42.718550Z"
    },
    "papermill": {
     "duration": 0.088235,
     "end_time": "2024-05-25T05:06:42.722339",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.634104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/super-glue-pretrained-network\")\n",
    "from models.matching import Matching\n",
    "from models.utils import (compute_pose_error, compute_epipolar_error,\n",
    "                          estimate_pose, make_matching_plot,\n",
    "                          error_colormap, AverageTimer, pose_auc, read_image,\n",
    "                          process_resize, frame2tensor,\n",
    "                          rotate_intrinsics, rotate_pose_inplane,\n",
    "                          scale_intrinsics)\n",
    "\n",
    "from torch.nn import functional as torchF  # For resizing tensor\n",
    "\n",
    "def sg_imread(path):\n",
    "    image = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)\n",
    "    return image\n",
    "\n",
    "# Preprocess\n",
    "def sg_read_image(image, device, resize):\n",
    "    w, h = image.shape[1], image.shape[0]\n",
    "    w_new, h_new = process_resize(w, h, [resize,])\n",
    "    \n",
    "    unit_shape = 8\n",
    "    w_new = w_new // unit_shape * unit_shape\n",
    "    h_new = h_new // unit_shape * unit_shape\n",
    "    \n",
    "    scales = (float(w) / float(w_new), float(h) / float(h_new))\n",
    "    image = cv2.resize(image.astype('float32'), (w_new, h_new))\n",
    "\n",
    "    inp = frame2tensor(image, \"cpu\")\n",
    "    return image, inp, scales, (h, w)\n",
    "\n",
    "class SGDataset(Dataset):\n",
    "    def __init__(self, fnames1, fnames2, resize_to, device):\n",
    "        self.fnames1 = fnames1\n",
    "        self.fnames2 = fnames2\n",
    "        self.resize_to = resize_to\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname1 = self.fnames1[idx]\n",
    "        fname2 = self.fnames2[idx]\n",
    "                \n",
    "        im1, im2 = cv2.imread(fname1, cv2.IMREAD_GRAYSCALE), cv2.imread(fname2, cv2.IMREAD_GRAYSCALE)\n",
    "        _, image1, scale1, ori_shape1 = sg_read_image(im1, self.device, self.resize_to)\n",
    "        _, image2, scale2, ori_shape2 = sg_read_image(im2, self.device, self.resize_to)\n",
    "        return image1, image2, torch.tensor([idx]), torch.tensor(ori_shape1), torch.tensor(ori_shape2)\n",
    "\n",
    "def get_superglue_dataloader(images1, images2, resize_to, device, batch_size=1):\n",
    "    dataset = SGDataset(images1, images2, resize_to, device)\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=2,\n",
    "        drop_last=False\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def detect_superglue(\n",
    "    img_fnames, index_pairs, feature_dir, device, sg_config, file_keypoints, \n",
    "    resize_to=750, min_matches=15\n",
    "):    \n",
    "    t=time()\n",
    "\n",
    "    matcher_superglue = Matching(sg_config).eval().to(device)\n",
    "\n",
    "    fnames1, fnames2, idxs1, idxs2 = [], [], [], []\n",
    "    for pair_idx in progress_bar(index_pairs):\n",
    "        idx1, idx2 = pair_idx\n",
    "        fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "        fnames1.append(fname1)\n",
    "        fnames2.append(fname2)\n",
    "        idxs1.append(idx1)\n",
    "        idxs2.append(idx2)\n",
    "        \n",
    "    dataloader = get_superglue_dataloader( fnames1, fnames2, resize_to, device)\n",
    "\n",
    "    cnt_pairs = 0\n",
    "\n",
    "    with h5py.File(file_keypoints, mode='w') as f_match:\n",
    "        for X in dataloader:\n",
    "            image1, image2, idx, ori_shape_1, ori_shape_2 = X\n",
    "\n",
    "            fname1, fname2 = fnames1[idx], fnames2[idx]\n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "            \n",
    "            pred = matcher_superglue({\"image0\": image1[0].to(device), \"image1\": image2[0].to(device)})\n",
    "            pred = {k: v[0].detach().cpu().numpy().copy() for k, v in pred.items()}\n",
    "            mkpts1, mkpts2 = pred[\"keypoints0\"], pred[\"keypoints1\"]\n",
    "            matches, conf = pred[\"matches0\"], pred[\"matching_scores0\"]\n",
    "\n",
    "            valid = matches > -1\n",
    "            mkpts1 = mkpts1[valid]\n",
    "            mkpts2 = mkpts2[matches[valid]]\n",
    "            mconf = conf[valid]\n",
    "\n",
    "            ori_shape_1 = ori_shape_1[0].numpy()\n",
    "            ori_shape_2 = ori_shape_2[0].numpy()\n",
    "            \n",
    "            # Scaling coords\n",
    "            mkpts1[:,0] = mkpts1[:,0] * ori_shape_1[1] / image1[0].shape[3]   # X\n",
    "            mkpts1[:,1] = mkpts1[:,1] * ori_shape_1[0] / image1[0].shape[2]   # Y\n",
    "            mkpts2[:,0] = mkpts2[:,0] * ori_shape_2[1] / image2[0].shape[3]   # X\n",
    "            mkpts2[:,1] = mkpts2[:,1] * ori_shape_2[0] / image2[0].shape[2]   # Y  \n",
    "            \n",
    "            n_matches = mconf.shape[0]\n",
    "            \n",
    "            group  = f_match.require_group(key1)\n",
    "            if n_matches >= min_matches:\n",
    "                group.create_dataset(key2, data=np.concatenate([mkpts1, mkpts2], axis=1).astype(np.float32))\n",
    "                cnt_pairs+=1\n",
    "                print (f'{key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair(superglue)')            \n",
    "            else:\n",
    "                print (f'{key1}-{key2}: {n_matches} matches --> skipped')            \n",
    "\n",
    "    gc.collect()\n",
    "    t=time() -t \n",
    "    print(f'Features matched in  {t:.4f} sec')\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51703499",
   "metadata": {
    "papermill": {
     "duration": 0.014771,
     "end_time": "2024-05-25T05:06:42.755127",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.740356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keypoints: DKM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12391b15",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.781952Z",
     "iopub.status.busy": "2024-05-25T05:06:42.781616Z",
     "iopub.status.idle": "2024-05-25T05:06:42.811533Z",
     "shell.execute_reply": "2024-05-25T05:06:42.810548Z"
    },
    "papermill": {
     "duration": 0.045883,
     "end_time": "2024-05-25T05:06:42.813684",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.767801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DKMDataset(Dataset):\n",
    "    def __init__(self, fnames1, fnames2, resize_to, device):\n",
    "        self.fnames1 = fnames1\n",
    "        self.fnames2 = fnames2\n",
    "        self.resize_to = resize_to\n",
    "        self.device = device\n",
    "        self.test_transform = get_tuple_transform_ops(\n",
    "            resize=self.resize_to, normalize=True\n",
    "        )\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname1 = self.fnames1[idx]\n",
    "        fname2 = self.fnames2[idx]\n",
    "                \n",
    "        im1, im2 = Image.open(fname1), Image.open(fname2)\n",
    "        ori_shape_1 = im1.size\n",
    "        ori_shape_2 = im2.size\n",
    "        image1, image2 = self.test_transform((im1, im2))\n",
    "        return image1, image2, torch.tensor([idx]), torch.tensor(ori_shape_1), torch.tensor(ori_shape_2)\n",
    "\n",
    "def get_dkm_dataloader(images1, images2, resize_to, device, batch_size=4):\n",
    "    dataset = DKMDataset(images1, images2, resize_to, device)\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=2,\n",
    "        drop_last=False\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def get_dkm_mkpts(dkm_model, bimgs1, bimgs2, shapes1, shapes2, detection_threshold=0.5, num_features = 2000, min_matches=15):\n",
    "    dense_matches, dense_certainty = dkm_model.match(bimgs1, bimgs2, batched=True)\n",
    "    print(\"***\", dense_matches.shape, dense_certainty.shape)\n",
    "\n",
    "    store_mkpts1, store_mkpts2, store_mconf = [], [], []\n",
    "    # drop low confidence pairs\n",
    "    for b in range(dense_matches.shape[0]):\n",
    "        u_dense_matches = dense_matches[b, dense_certainty[b,...].sqrt() >= detection_threshold, :]\n",
    "        u_dense_certainty = dense_certainty[b, dense_certainty[b,...].sqrt() >= detection_threshold]\n",
    "    \n",
    "        if u_dense_matches.shape[0] > num_features:\n",
    "            u_dense_matches, u_dense_certainty = dkm_model.sample( u_dense_matches, u_dense_certainty, num=num_features)\n",
    "        \n",
    "        u_dense_matches = u_dense_matches.reshape((-1, 4))\n",
    "        u_dense_certainty = u_dense_certainty.reshape((-1,))\n",
    "    \n",
    "        mkpts1 = u_dense_matches[:, :2]\n",
    "        mkpts2 = u_dense_matches[:, 2:]\n",
    "        \n",
    "        w1, h1 = shapes1[b, :]\n",
    "        w2, h2 = shapes2[b, :]\n",
    "\n",
    "        mkpts1[:, 0] = ((mkpts1[:, 0] + 1)/2) * w1\n",
    "        mkpts1[:, 1] = ((mkpts1[:, 1] + 1)/2) * h1\n",
    "\n",
    "        mkpts2[:, 0] = ((mkpts2[:, 0] + 1)/2) * w2\n",
    "        mkpts2[:, 1] = ((mkpts2[:, 1] + 1)/2) * h2\n",
    "\n",
    "        mkpts1 = mkpts1.cpu().detach().numpy()\n",
    "        mkpts2 = mkpts2.cpu().detach().numpy()\n",
    "        mconf  = u_dense_certainty.sqrt().cpu().detach().numpy()\n",
    "\n",
    "        \n",
    "        if mconf.shape[0] > min_matches:\n",
    "            try:\n",
    "                # calc Fundamental matrix from keypoints\n",
    "                F, inliers = cv2.findFundamentalMat(mkpts1, mkpts2, cv2.USAC_MAGSAC, 0.200, 0.999, 2000)\n",
    "                inliers = inliers > 0\n",
    "                mkpts1 = mkpts1[inliers[:,0]]\n",
    "                mkpts2 = mkpts2[inliers[:,0]]\n",
    "                mconf  = mconf[inliers[:,0]]\n",
    "                #print(\"---\", mconf.shape)\n",
    "                if mconf.shape[0] > 3000:\n",
    "                    rand_idx = np.random.choice(range(mconf.shape[0]), 3000, replace=False)\n",
    "                    mkpts1 = mkpts1[rand_idx, :]\n",
    "                    mkpts2 = mkpts2[rand_idx, :]\n",
    "                    mconf  = mconf[rand_idx]\n",
    "            except:\n",
    "                mkpts1 = np.empty((0,2))\n",
    "                mkpts2 = np.empty((0,2))\n",
    "                mconf = np.empty((0,))\n",
    "        \n",
    "        store_mkpts1.append(mkpts1)\n",
    "        store_mkpts2.append(mkpts2)\n",
    "        store_mconf.append(mconf)\n",
    "    return store_mkpts1, store_mkpts2, store_mconf\n",
    "\n",
    "def detect_dkm(\n",
    "    img_fnames, index_pairs, feature_dir, device, \n",
    "    resize_to=(540, 720), \n",
    "    detection_threshold=0.3, \n",
    "    num_features=2000, \n",
    "    min_matches=30,\n",
    "):\n",
    "    t=time()\n",
    "    dkm_model = DKMv3_outdoor(device=device)\n",
    "    dkm_model.upsample_preds=False\n",
    "\n",
    "    fnames1, fnames2 = [], []\n",
    "    for pair_idx in progress_bar(index_pairs):\n",
    "        idx1, idx2 = pair_idx\n",
    "        fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "        fnames1.append(fname1)\n",
    "        fnames2.append(fname2)\n",
    "        \n",
    "    cnt_pairs = 0\n",
    "    with h5py.File(f'{feature_dir}/matches_dkm.h5', mode='w') as f_match:    \n",
    "        dataloader = get_dkm_dataloader(fnames1, fnames2, resize_to, device, batch_size=4)\n",
    "        for X in tqdm(dataloader):\n",
    "            images1, images2, idxs, shapes1, shapes2 = X\n",
    "            store_mkpts1, store_mkpts2, store_mconf = get_dkm_mkpts(\n",
    "                dkm_model, images1.to(device), images2.to(device), shapes1, shapes2, \n",
    "                detection_threshold=detection_threshold, num_features = num_features, min_matches=min_matches,\n",
    "            )\n",
    "            \n",
    "            for b in range(images1.shape[0]):\n",
    "                mkpts1 = store_mkpts1[b]\n",
    "                mkpts2 = store_mkpts2[b]\n",
    "                mconf = store_mconf[b]\n",
    "                file1 = fnames1[idxs[b]]\n",
    "                file2 = fnames2[idxs[b]]\n",
    "                key1, key2 = file1.split('/')[-1], file2.split('/')[-1]\n",
    "            \n",
    "                n_matches = mconf.shape[0]\n",
    "                print (f'{key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair(dkm)')            \n",
    "\n",
    "                group  = f_match.require_group(key1)\n",
    "                if n_matches >= min_matches:\n",
    "                    group.create_dataset(key2, data=np.concatenate([mkpts1, mkpts2], axis=1).astype(np.float32))\n",
    "                    cnt_pairs+=1\n",
    "    gc.collect()\n",
    "    t=time() -t \n",
    "    print(f'Features matched in  {t:.4f} sec')\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e4acac",
   "metadata": {
    "papermill": {
     "duration": 0.012326,
     "end_time": "2024-05-25T05:06:42.838733",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.826407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keypoints: LoFTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "833b2e34",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.865239Z",
     "iopub.status.busy": "2024-05-25T05:06:42.864906Z",
     "iopub.status.idle": "2024-05-25T05:06:42.887472Z",
     "shell.execute_reply": "2024-05-25T05:06:42.886547Z"
    },
    "papermill": {
     "duration": 0.038542,
     "end_time": "2024-05-25T05:06:42.889447",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.850905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LoFTRDataset(Dataset):\n",
    "    def __init__(self, fnames1, fnames2, idxs1, idxs2, resize_small_edge_to, device):\n",
    "        self.fnames1 = fnames1\n",
    "        self.fnames2 = fnames2\n",
    "        self.keys1 = [ fname.split('/')[-1] for fname in fnames1 ]\n",
    "        self.keys2 = [ fname.split('/')[-1] for fname in fnames2 ]\n",
    "        self.idxs1 = idxs1\n",
    "        self.idxs2 = idxs2\n",
    "        self.resize_small_edge_to = resize_small_edge_to\n",
    "        self.device = device\n",
    "        self.round_unit = 16\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images1)\n",
    "\n",
    "    def load_torch_image(self, fname, device):\n",
    "        img = cv2.imread(fname)\n",
    "        original_shape = img.shape\n",
    "        ratio = self.resize_small_edge_to / min([img.shape[0], img.shape[1]])\n",
    "        w = int(img.shape[1] * ratio) # int( (img.shape[1] * ratio) // self.round_unit * self.round_unit )\n",
    "        h = int(img.shape[0] * ratio) # int( (img.shape[0] * ratio) // self.round_unit * self.round_unit )\n",
    "        img_resized = cv2.resize(img, (w, h))\n",
    "        img_resized = K.image_to_tensor(img_resized, False).float() /255.\n",
    "        img_resized = K.color.bgr_to_rgb(img_resized)\n",
    "        img_resized = K.color.rgb_to_grayscale(img_resized)\n",
    "        return img_resized.to(device), original_shape\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname1 = self.fnames1[idx]\n",
    "        fname2 = self.fnames2[idx]\n",
    "        image1, ori_shape_1 = self.load_torch_image(fname1, device)\n",
    "        image2, ori_shape_2 = self.load_torch_image(fname2, device)\n",
    "\n",
    "        return image1, image2, self.keys1[idx], self.keys2[idx], self.idxs1[idx], self.idxs2[idx], ori_shape_1, ori_shape_2\n",
    "\n",
    "def get_loftr_dataloader(images1, images2, idxs1, idxs2, resize_small_edge_to, device, batch_size=1):\n",
    "    dataset = LoFTRDataset(images1, images2, idxs1, idxs2, resize_small_edge_to, device)\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=2,\n",
    "        drop_last=False\n",
    "    )\n",
    "    return dataset\n",
    "    \n",
    "def detect_loftr(img_fnames, index_pairs, feature_dir, device, file_keypoints, resize_small_edge_to=750, min_matches=15):\n",
    "    t=time()\n",
    "\n",
    "    matcher = LoFTR(pretrained=None)\n",
    "    matcher.load_state_dict(torch.load(\"../input/loftr/pytorch/outdoor/1/loftr_outdoor.ckpt\")['state_dict'])\n",
    "    matcher = matcher.to(device).eval()\n",
    "\n",
    "    fnames1, fnames2, idxs1, idxs2 = [], [], [], []\n",
    "    for pair_idx in progress_bar(index_pairs):\n",
    "        idx1, idx2 = pair_idx\n",
    "        fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "        fnames1.append(fname1)\n",
    "        fnames2.append(fname2)\n",
    "        idxs1.append(idx1)\n",
    "        idxs2.append(idx2)\n",
    "        \n",
    "        \n",
    "    dataloader = get_loftr_dataloader( fnames1, fnames2, idxs1, idxs2, resize_small_edge_to, device)\n",
    "\n",
    "    cnt_pairs = 0\n",
    "\n",
    "    with h5py.File(file_keypoints, mode='w') as f_match:    \n",
    "        store_mkpts = {}\n",
    "        for X in tqdm(dataloader):\n",
    "            image1, image2, key1, key2, idx1, idx2, ori_shape_1, ori_shape_2 = X\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                correspondences = matcher( {\"image0\": image1.to(device),\"image1\": image2.to(device)} )\n",
    "                mkpts1 = correspondences['keypoints0'].cpu().numpy()\n",
    "                mkpts2 = correspondences['keypoints1'].cpu().numpy()\n",
    "                mconf  = correspondences['confidence'].cpu().numpy()\n",
    "\n",
    "            mkpts1[:,0] *= (float(ori_shape_1[1]) / float(image1.shape[3]))\n",
    "            mkpts1[:,1] *= (float(ori_shape_1[0]) / float(image1.shape[2]))\n",
    "\n",
    "            mkpts2[:,0] *= (float(ori_shape_2[1]) / float(image2.shape[3]))\n",
    "            mkpts2[:,1] *= (float(ori_shape_2[0]) / float(image2.shape[2]))\n",
    "            \n",
    "            n_matches = mconf.shape[0]\n",
    "            \n",
    "            group  = f_match.require_group(key1)\n",
    "            if n_matches >= min_matches:\n",
    "                group.create_dataset(key2, data=np.concatenate([mkpts1, mkpts2], axis=1).astype(np.float32))\n",
    "                cnt_pairs+=1\n",
    "                print (f'{key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair(loftr)')\n",
    "            else:\n",
    "                print (f'{key1}-{key2}: {n_matches} matches --> skipped')\n",
    "    gc.collect()\n",
    "    t=time() -t \n",
    "    print(f'Features matched in  {t:.4f} sec')\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeeddfd",
   "metadata": {
    "papermill": {
     "duration": 0.011875,
     "end_time": "2024-05-25T05:06:42.913411",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.901536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keypoints: DKM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "393c81d7",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:42.939335Z",
     "iopub.status.busy": "2024-05-25T05:06:42.939053Z",
     "iopub.status.idle": "2024-05-25T05:06:42.964906Z",
     "shell.execute_reply": "2024-05-25T05:06:42.964173Z"
    },
    "papermill": {
     "duration": 0.041514,
     "end_time": "2024-05-25T05:06:42.967394",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.925880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DKMDataset(Dataset):\n",
    "    def __init__(self, fnames1, fnames2, resize_to, device):\n",
    "        self.fnames1 = fnames1\n",
    "        self.fnames2 = fnames2\n",
    "        self.resize_to = resize_to\n",
    "        self.device = device\n",
    "        self.test_transform = get_tuple_transform_ops(\n",
    "            resize=self.resize_to, normalize=True\n",
    "        )\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname1 = self.fnames1[idx]\n",
    "        fname2 = self.fnames2[idx]\n",
    "                \n",
    "        im1, im2 = Image.open(fname1), Image.open(fname2)\n",
    "        ori_shape_1 = im1.size\n",
    "        ori_shape_2 = im2.size\n",
    "        image1, image2 = self.test_transform((im1, im2))\n",
    "        return image1, image2, torch.tensor([idx]), torch.tensor(ori_shape_1), torch.tensor(ori_shape_2)\n",
    "\n",
    "def get_dkm_dataloader(images1, images2, resize_to, device, batch_size=4):\n",
    "    dataset = DKMDataset(images1, images2, resize_to, device)\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=2,\n",
    "        drop_last=False\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def get_dkm_mkpts(dkm_model, bimgs1, bimgs2, shapes1, shapes2, detection_threshold=0.5, num_features = 2000, min_matches=15):\n",
    "    dense_matches, dense_certainty = dkm_model.match(bimgs1, bimgs2, batched=True)\n",
    "\n",
    "    store_mkpts1, store_mkpts2, store_mconf = [], [], []\n",
    "    # drop low confidence pairs\n",
    "    for b in range(dense_matches.shape[0]):\n",
    "        u_dense_matches = dense_matches[b, dense_certainty[b,...].sqrt() >= detection_threshold, :]\n",
    "        u_dense_certainty = dense_certainty[b, dense_certainty[b,...].sqrt() >= detection_threshold]\n",
    "    \n",
    "        if u_dense_matches.shape[0] > num_features:\n",
    "            u_dense_matches, u_dense_certainty = dkm_model.sample( u_dense_matches, u_dense_certainty, num=num_features)\n",
    "        \n",
    "        u_dense_matches = u_dense_matches.reshape((-1, 4))\n",
    "        u_dense_certainty = u_dense_certainty.reshape((-1,))\n",
    "    \n",
    "        mkpts1 = u_dense_matches[:, :2]\n",
    "        mkpts2 = u_dense_matches[:, 2:]\n",
    "        \n",
    "        w1, h1 = shapes1[b, :]\n",
    "        w2, h2 = shapes2[b, :]\n",
    "\n",
    "        mkpts1[:, 0] = ((mkpts1[:, 0] + 1)/2) * w1\n",
    "        mkpts1[:, 1] = ((mkpts1[:, 1] + 1)/2) * h1\n",
    "\n",
    "        mkpts2[:, 0] = ((mkpts2[:, 0] + 1)/2) * w2\n",
    "        mkpts2[:, 1] = ((mkpts2[:, 1] + 1)/2) * h2\n",
    "\n",
    "        mkpts1 = mkpts1.cpu().detach().numpy()\n",
    "        mkpts2 = mkpts2.cpu().detach().numpy()\n",
    "        mconf  = u_dense_certainty.sqrt().cpu().detach().numpy()\n",
    "\n",
    "        if mconf.shape[0] > min_matches:\n",
    "            try:\n",
    "                # calc Fundamental matrix from keypoints\n",
    "                F, inliers = cv2.findFundamentalMat(mkpts1, mkpts2, cv2.USAC_MAGSAC, 0.200, 0.999, 2000)\n",
    "                inliers = inliers > 0\n",
    "                mkpts1 = mkpts1[inliers[:,0]]\n",
    "                mkpts2 = mkpts2[inliers[:,0]]\n",
    "                mconf  = mconf[inliers[:,0]]\n",
    "            except:\n",
    "                pass\n",
    "        store_mkpts1.append(mkpts1)\n",
    "        store_mkpts2.append(mkpts2)\n",
    "        store_mconf.append(mconf)\n",
    "    return store_mkpts1, store_mkpts2, store_mconf\n",
    "\n",
    "def detect_dkm(\n",
    "    img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
    "    resize_to=(540, 720), \n",
    "    detection_threshold=0.4, \n",
    "    num_features=2000, \n",
    "    min_matches=15\n",
    "):\n",
    "    t=time()\n",
    "    dkm_model = DKMv3_outdoor(device=device)\n",
    "    dkm_model.upsample_preds=False\n",
    "\n",
    "    fnames1, fnames2 = [], []\n",
    "    for pair_idx in progress_bar(index_pairs):\n",
    "        idx1, idx2 = pair_idx\n",
    "        fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "        fnames1.append(fname1)\n",
    "        fnames2.append(fname2)\n",
    "        \n",
    "    cnt_pairs = 0\n",
    "    with h5py.File(file_keypoints, mode='w') as f_match:    \n",
    "        dataloader = get_dkm_dataloader(fnames1, fnames2, resize_to, device, batch_size=4)\n",
    "        for X in tqdm(dataloader):\n",
    "            images1, images2, idxs, shapes1, shapes2 = X\n",
    "            store_mkpts1, store_mkpts2, store_mconf = get_dkm_mkpts(\n",
    "                dkm_model, images1.to(device), images2.to(device), shapes1, shapes2, \n",
    "                detection_threshold=detection_threshold, num_features = num_features, min_matches=min_matches,\n",
    "            )\n",
    "            \n",
    "            for b in range(images1.shape[0]):\n",
    "                mkpts1 = store_mkpts1[b]\n",
    "                mkpts2 = store_mkpts2[b]\n",
    "                mconf = store_mconf[b]\n",
    "                file1 = fnames1[idxs[b]]\n",
    "                file2 = fnames2[idxs[b]]\n",
    "                key1, key2 = file1.split('/')[-1], file2.split('/')[-1]\n",
    "            \n",
    "                n_matches = mconf.shape[0]\n",
    "\n",
    "                group  = f_match.require_group(key1)\n",
    "                if n_matches >= min_matches:\n",
    "                    group.create_dataset(key2, data=np.concatenate([mkpts1, mkpts2], axis=1).astype(np.float32))\n",
    "                    cnt_pairs+=1\n",
    "                    print (f'{key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair(dkm)')\n",
    "                else:\n",
    "                    print (f'{key1}-{key2}: {n_matches} matches --> skipped')\n",
    "\n",
    "    gc.collect()\n",
    "    t=time() -t \n",
    "    print(f'Features matched in  {t:.4f} sec')\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b417b",
   "metadata": {
    "papermill": {
     "duration": 0.01189,
     "end_time": "2024-05-25T05:06:42.991986",
     "exception": false,
     "start_time": "2024-05-25T05:06:42.980096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keypoints merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b1a7124",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:43.018252Z",
     "iopub.status.busy": "2024-05-25T05:06:43.017378Z",
     "iopub.status.idle": "2024-05-25T05:06:43.043080Z",
     "shell.execute_reply": "2024-05-25T05:06:43.042148Z"
    },
    "papermill": {
     "duration": 0.040881,
     "end_time": "2024-05-25T05:06:43.045097",
     "exception": false,
     "start_time": "2024-05-25T05:06:43.004216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_unique_idxs(A, dim=0):\n",
    "    # https://stackoverflow.com/questions/72001505/how-to-get-unique-elements-and-their-firstly-appeared-indices-of-a-pytorch-tenso\n",
    "    unique, idx, counts = torch.unique(A, dim=dim, sorted=True, return_inverse=True, return_counts=True)\n",
    "    _, ind_sorted = torch.sort(idx, stable=True)\n",
    "    cum_sum = counts.cumsum(0)\n",
    "    cum_sum = torch.cat((torch.tensor([0],device=cum_sum.device), cum_sum[:-1]))\n",
    "    first_indices = ind_sorted[cum_sum]\n",
    "    return first_indices\n",
    "\n",
    "def get_keypoint_from_h5(fp, key1, key2):\n",
    "    rc = -1\n",
    "    try:\n",
    "        kpts = np.array(fp[key1][key2])\n",
    "        rc = 0\n",
    "        return (rc, kpts)\n",
    "    except:\n",
    "        return (rc, None)\n",
    "\n",
    "def get_keypoint_from_multi_h5(fps, key1, key2):\n",
    "    list_mkpts = []\n",
    "    for fp in fps:\n",
    "        rc, mkpts = get_keypoint_from_h5(fp, key1, key2)\n",
    "        if rc == 0:\n",
    "            list_mkpts.append(mkpts)\n",
    "    if len(list_mkpts) > 0:\n",
    "        list_mkpts = np.concatenate(list_mkpts, axis=0)\n",
    "    else:\n",
    "        list_mkpts = None\n",
    "    return list_mkpts\n",
    "\n",
    "def keypoints_merger(\n",
    "    img_fnames,\n",
    "    index_pairs,\n",
    "    files_keypoints,\n",
    "    feature_dir = 'featureout',\n",
    "):\n",
    "    # open h5 files\n",
    "    fps = [ h5py.File(file, mode=\"r\") for file in files_keypoints ]\n",
    "\n",
    "    # temprary file\n",
    "    with h5py.File(f'{feature_dir}/merge_tmp.h5', mode='w') as f_match:\n",
    "        counter = 0\n",
    "        for pair_idx in progress_bar(index_pairs):\n",
    "            idx1, idx2 = pair_idx\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "\n",
    "            # extract keypoints\n",
    "            mkpts = get_keypoint_from_multi_h5(fps, key1, key2)\n",
    "            if mkpts is None:\n",
    "                print(f\"skipped key1={key1}, key2={key2}\")\n",
    "                continue\n",
    "                \n",
    "            print (f'{key1}-{key2}: {mkpts.shape[0]} matches')            \n",
    "            # regist tmp file\n",
    "            group  = f_match.require_group(key1)\n",
    "            group.create_dataset(key2, data=mkpts)\n",
    "            counter += 1\n",
    "    print( f\"Ensembled pairs : {counter} pairs\" )\n",
    "    for fp in fps:\n",
    "        fp.close()\n",
    "    \n",
    "    # Let's find unique loftr pixels and group them together.\n",
    "    kpts = defaultdict(list)\n",
    "    match_indexes = defaultdict(dict)\n",
    "    total_kpts=defaultdict(int)\n",
    "    with h5py.File(f'{feature_dir}/merge_tmp.h5', mode='r') as f_match:\n",
    "        for k1 in f_match.keys():\n",
    "            group  = f_match[k1]\n",
    "            for k2 in group.keys():\n",
    "                matches = group[k2][...]\n",
    "                total_kpts[k1]\n",
    "                kpts[k1].append(matches[:, :2])\n",
    "                kpts[k2].append(matches[:, 2:])\n",
    "                current_match = torch.arange(len(matches)).reshape(-1, 1).repeat(1, 2)\n",
    "                current_match[:, 0]+=total_kpts[k1]\n",
    "                current_match[:, 1]+=total_kpts[k2]\n",
    "                total_kpts[k1]+=len(matches)\n",
    "                total_kpts[k2]+=len(matches)\n",
    "                match_indexes[k1][k2]=current_match\n",
    "\n",
    "    for k in kpts.keys():\n",
    "        kpts[k] = np.round(np.concatenate(kpts[k], axis=0))\n",
    "    unique_kpts = {}\n",
    "    unique_match_idxs = {}\n",
    "    out_match = defaultdict(dict)\n",
    "    for k in kpts.keys():\n",
    "        uniq_kps, uniq_reverse_idxs = torch.unique(torch.from_numpy(kpts[k]),dim=0, return_inverse=True)\n",
    "        unique_match_idxs[k] = uniq_reverse_idxs\n",
    "        unique_kpts[k] = uniq_kps.numpy()\n",
    "    for k1, group in match_indexes.items():\n",
    "        for k2, m in group.items():\n",
    "            m2 = deepcopy(m)\n",
    "            m2[:,0] = unique_match_idxs[k1][m2[:,0]]\n",
    "            m2[:,1] = unique_match_idxs[k2][m2[:,1]]\n",
    "            mkpts = np.concatenate([unique_kpts[k1][ m2[:,0]],\n",
    "                                    unique_kpts[k2][  m2[:,1]],\n",
    "                                   ],\n",
    "                                   axis=1)\n",
    "            unique_idxs_current = get_unique_idxs(torch.from_numpy(mkpts), dim=0)\n",
    "            m2_semiclean = m2[unique_idxs_current]\n",
    "            unique_idxs_current1 = get_unique_idxs(m2_semiclean[:, 0], dim=0)\n",
    "            m2_semiclean = m2_semiclean[unique_idxs_current1]\n",
    "            unique_idxs_current2 = get_unique_idxs(m2_semiclean[:, 1], dim=0)\n",
    "            m2_semiclean2 = m2_semiclean[unique_idxs_current2]\n",
    "            out_match[k1][k2] = m2_semiclean2.numpy()\n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp:\n",
    "        for k, kpts1 in unique_kpts.items():\n",
    "            f_kp[k] = kpts1\n",
    "    \n",
    "    with h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n",
    "        for k1, gr in out_match.items():\n",
    "            group  = f_match.require_group(k1)\n",
    "            for k2, match in gr.items():\n",
    "                group[k2] = match\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84d2ae",
   "metadata": {
    "papermill": {
     "duration": 0.012264,
     "end_time": "2024-05-25T05:06:43.069593",
     "exception": false,
     "start_time": "2024-05-25T05:06:43.057329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ff4c57c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:43.095285Z",
     "iopub.status.busy": "2024-05-25T05:06:43.094961Z",
     "iopub.status.idle": "2024-05-25T05:06:43.103801Z",
     "shell.execute_reply": "2024-05-25T05:06:43.102922Z"
    },
    "papermill": {
     "duration": 0.024287,
     "end_time": "2024-05-25T05:06:43.105958",
     "exception": false,
     "start_time": "2024-05-25T05:06:43.081671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def arr_to_str(a):\n",
    "    return ';'.join([str(x) for x in a.reshape(-1)])\n",
    "\n",
    "# Function to create a submission file.\n",
    "def create_submission(out_results, data_dict):\n",
    "    with open(f'submission.csv', 'w') as f:\n",
    "        f.write('image_path,dataset,scene,rotation_matrix,translation_vector\\n')\n",
    "        for dataset in data_dict:\n",
    "            if dataset in out_results:\n",
    "                res = out_results[dataset]\n",
    "            else:\n",
    "                res = {}\n",
    "            for scene in data_dict[dataset]:\n",
    "                if scene in res:\n",
    "                    scene_res = res[scene]\n",
    "                else:\n",
    "                    scene_res = {\"R\":{}, \"t\":{}}\n",
    "                for image in data_dict[dataset][scene]:\n",
    "                    if image in scene_res:\n",
    "                        print (image)\n",
    "                        R = scene_res[image]['R'].reshape(-1)\n",
    "                        T = scene_res[image]['t'].reshape(-1)\n",
    "                    else:\n",
    "                        R = np.eye(3).reshape(-1)\n",
    "                        T = np.zeros((3))\n",
    "                    f.write(f'{image},{dataset},{scene},{arr_to_str(R)},{arr_to_str(T)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915b613a",
   "metadata": {
    "papermill": {
     "duration": 0.012214,
     "end_time": "2024-05-25T05:06:43.130700",
     "exception": false,
     "start_time": "2024-05-25T05:06:43.118486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8929795c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:43.156399Z",
     "iopub.status.busy": "2024-05-25T05:06:43.156060Z",
     "iopub.status.idle": "2024-05-25T05:06:43.165760Z",
     "shell.execute_reply": "2024-05-25T05:06:43.164900Z"
    },
    "papermill": {
     "duration": 0.025158,
     "end_time": "2024-05-25T05:06:43.167860",
     "exception": false,
     "start_time": "2024-05-25T05:06:43.142702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = '/kaggle/input/image-matching-challenge-2024'\n",
    "DEBUG = False\n",
    "DUMP = False\n",
    "\n",
    "# Get data from csv.\n",
    "data_dict = {}\n",
    "with open(f'{src}/sample_submission.csv', 'r') as f:\n",
    "    for i, l in enumerate(f):\n",
    "        # Skip header.\n",
    "        if l and i > 0:\n",
    "            image, dataset, scene, _, _ = l.strip().split(',')\n",
    "            if dataset not in data_dict:\n",
    "                data_dict[dataset] = {}\n",
    "            if scene not in data_dict[dataset]:\n",
    "                data_dict[dataset][scene] = []\n",
    "            data_dict[dataset][scene].append(image)\n",
    "            \n",
    "            #if len(data_dict[dataset][scene]) == 21:\n",
    "            #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "296ac123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:43.193719Z",
     "iopub.status.busy": "2024-05-25T05:06:43.193101Z",
     "iopub.status.idle": "2024-05-25T05:06:43.198181Z",
     "shell.execute_reply": "2024-05-25T05:06:43.197168Z"
    },
    "papermill": {
     "duration": 0.019776,
     "end_time": "2024-05-25T05:06:43.200000",
     "exception": false,
     "start_time": "2024-05-25T05:06:43.180224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "church / church -> 41 images\n"
     ]
    }
   ],
   "source": [
    "for dataset in data_dict:\n",
    "    for scene in data_dict[dataset]:\n",
    "        print(f'{dataset} / {scene} -> {len(data_dict[dataset][scene])} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "355a2abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:43.225508Z",
     "iopub.status.busy": "2024-05-25T05:06:43.225192Z",
     "iopub.status.idle": "2024-05-25T05:06:43.229744Z",
     "shell.execute_reply": "2024-05-25T05:06:43.228946Z"
    },
    "papermill": {
     "duration": 0.019408,
     "end_time": "2024-05-25T05:06:43.231559",
     "exception": false,
     "start_time": "2024-05-25T05:06:43.212151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_results = {}\n",
    "timings = {\"shortlisting\":[],\n",
    "           \"feature_detection\": [],\n",
    "           \"feature_matching\":[],\n",
    "           \"RANSAC\": [],\n",
    "           \"Reconstruction\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1978ff74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:06:43.257223Z",
     "iopub.status.busy": "2024-05-25T05:06:43.256954Z",
     "iopub.status.idle": "2024-05-25T05:45:53.890382Z",
     "shell.execute_reply": "2024-05-25T05:45:53.889359Z"
    },
    "papermill": {
     "duration": 2350.649204,
     "end_time": "2024-05-25T05:45:53.892825",
     "exception": false,
     "start_time": "2024-05-25T05:06:43.243621",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction done in  1219.8819 sec\n",
      "Looking for the best reconstruction\n",
      "0 Reconstruction:\n",
      "\tnum_reg_images = 37\n",
      "\tnum_cameras = 37\n",
      "\tnum_points3D = 74539\n",
      "\tnum_observations = 329269\n",
      "\tmean_track_length = 4.41741\n",
      "\tmean_observations_per_image = 8899.16\n",
      "\tmean_reprojection_error = 0.786836\n",
      "list_num_images = [37]\n",
      "Reconstruction:\n",
      "\tnum_reg_images = 37\n",
      "\tnum_cameras = 37\n",
      "\tnum_points3D = 74539\n",
      "\tnum_observations = 329269\n",
      "\tmean_track_length = 4.41741\n",
      "\tmean_observations_per_image = 8899.16\n",
      "\tmean_reprojection_error = 0.786836\n",
      "Registered: church / church -> 37 images\n",
      "Total: church / church -> 41 images\n",
      "test/church/images/00090.png\n",
      "test/church/images/00092.png\n",
      "test/church/images/00087.png\n",
      "test/church/images/00050.png\n",
      "test/church/images/00068.png\n",
      "test/church/images/00083.png\n",
      "test/church/images/00096.png\n",
      "test/church/images/00069.png\n",
      "test/church/images/00081.png\n",
      "test/church/images/00042.png\n",
      "test/church/images/00018.png\n",
      "test/church/images/00030.png\n",
      "test/church/images/00024.png\n",
      "test/church/images/00032.png\n",
      "test/church/images/00026.png\n",
      "test/church/images/00037.png\n",
      "test/church/images/00008.png\n",
      "test/church/images/00035.png\n",
      "test/church/images/00021.png\n",
      "test/church/images/00010.png\n",
      "test/church/images/00039.png\n",
      "test/church/images/00011.png\n",
      "test/church/images/00013.png\n",
      "test/church/images/00006.png\n",
      "test/church/images/00012.png\n",
      "test/church/images/00029.png\n",
      "test/church/images/00001.png\n",
      "test/church/images/00072.png\n",
      "test/church/images/00066.png\n",
      "test/church/images/00058.png\n",
      "test/church/images/00059.png\n",
      "test/church/images/00111.png\n",
      "test/church/images/00061.png\n",
      "test/church/images/00060.png\n",
      "test/church/images/00074.png\n",
      "test/church/images/00076.png\n",
      "test/church/images/00063.png\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "datasets = []\n",
    "for dataset in data_dict:\n",
    "    datasets.append(dataset)\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    if dataset not in out_results:\n",
    "        out_results[dataset] = {}\n",
    "    for scene in data_dict[dataset]:\n",
    "        print(scene)\n",
    "        # Fail gently if the notebook has not been submitted and the test data is not populated.\n",
    "        # You may want to run this on the training data in that case?\n",
    "        img_dir = f'{src}/test/{dataset}/images'\n",
    "        if not os.path.exists(img_dir):\n",
    "            continue\n",
    "        # Wrap the meaty part in a try-except block.\n",
    "        try:\n",
    "            out_results[dataset][scene] = {}\n",
    "            img_fnames = [f'{src}/{x}' for x in data_dict[dataset][scene]]\n",
    "            print (f\"Got {len(img_fnames)} images\")\n",
    "            feature_dir = f'featureout/{dataset}_{scene}'\n",
    "            if not os.path.isdir(feature_dir):\n",
    "                os.makedirs(feature_dir, exist_ok=True)\n",
    "\n",
    "            #############################################################\n",
    "            # get image pairs\n",
    "            #############################################################\n",
    "            t=time()\n",
    "            index_pairs = get_image_pairs_shortlist(img_fnames,\n",
    "                                  sim_th = 1.0, # should be strict\n",
    "                                  min_pairs = 50, # we select at least min_pairs PER IMAGE with biggest similarity\n",
    "                                  exhaustive_if_less = 50,\n",
    "                                  device=device)\n",
    "            t=time() -t \n",
    "            timings['shortlisting'].append(t)\n",
    "            print (f'{len(index_pairs)}, pairs to match, {t:.4f} sec')\n",
    "            gc.collect()\n",
    "            \n",
    "            #############################################################\n",
    "            # get keypoints\n",
    "            #############################################################\n",
    "            files_keypoints = []\n",
    "            if CONFIG.use_superglue:\n",
    "                resize_to = CONFIG.params_sg[\"resize_to\"]\n",
    "                file_keypoints = f\"{feature_dir}/matches_superglue_{resize_to}pix.h5\"\n",
    "                !rm -rf {file_keypoints}\n",
    "                t = detect_superglue(\n",
    "                    img_fnames, index_pairs, feature_dir, device, \n",
    "                    CONFIG.params_sg[\"sg_config\"], file_keypoints,\n",
    "                    resize_to=CONFIG.params_sg[\"resize_to\"], \n",
    "                    min_matches=CONFIG.params_sg[\"min_matches\"],\n",
    "                )\n",
    "                gc.collect()\n",
    "                files_keypoints.append( file_keypoints )\n",
    "                timings['feature_matching'].append(t)\n",
    "\n",
    "            if CONFIG.use_aliked_lightglue:\n",
    "                model_name = \"aliked\"\n",
    "                file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "                t = detect_lightglue_common(\n",
    "                    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints,\n",
    "                    resize_to=CONFIG.params_aliked_lightglue[\"resize_to\"],\n",
    "                    detection_threshold=CONFIG.params_aliked_lightglue[\"detection_threshold\"],\n",
    "                    num_features=CONFIG.params_aliked_lightglue[\"num_features\"],\n",
    "                    min_matches=CONFIG.params_aliked_lightglue[\"min_matches\"],\n",
    "                )\n",
    "                gc.collect()\n",
    "                files_keypoints.append(file_keypoints)\n",
    "                timings['feature_matching'].append(t)\n",
    "                \n",
    "            if CONFIG.use_doghardnet_lightglue:\n",
    "                model_name = \"doghardnet\"\n",
    "                file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "                t = detect_lightglue_common(\n",
    "                    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints,\n",
    "                    resize_to=CONFIG.params_doghardnet_lightglue[\"resize_to\"],\n",
    "                    detection_threshold=CONFIG.params_doghardnet_lightglue[\"detection_threshold\"],\n",
    "                    num_features=CONFIG.params_doghardnet_lightglue[\"num_features\"],\n",
    "                    min_matches=CONFIG.params_doghardnet_lightglue[\"min_matches\"],\n",
    "                )\n",
    "                gc.collect()\n",
    "                files_keypoints.append(file_keypoints)\n",
    "                timings['feature_matching'].append(t)\n",
    "                \n",
    "            if CONFIG.use_superpoint_lightglue:\n",
    "                model_name = \"superpoint\"\n",
    "                file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "                t = detect_lightglue_common(\n",
    "                    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints,\n",
    "                    resize_to=CONFIG.params_superpoint_lightglue[\"resize_to\"],\n",
    "                    detection_threshold=CONFIG.params_superpoint_lightglue[\"detection_threshold\"],\n",
    "                    num_features=CONFIG.params_superpoint_lightglue[\"num_features\"],\n",
    "                    min_matches=CONFIG.params_superpoint_lightglue[\"min_matches\"],\n",
    "                )\n",
    "                gc.collect()\n",
    "                files_keypoints.append(file_keypoints)\n",
    "                timings['feature_matching'].append(t)\n",
    "                \n",
    "            if CONFIG.use_loftr:\n",
    "                file_keypoints = f'{feature_dir}/matches_loftr_{CONFIG.params_loftr[\"resize_small_edge_to\"]}pix.h5'\n",
    "                t = detect_loftr(\n",
    "                    img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
    "                    resize_small_edge_to=CONFIG.params_loftr[\"resize_small_edge_to\"],\n",
    "                    min_matches=CONFIG.params_loftr[\"min_matches\"],\n",
    "                )\n",
    "                gc.collect()\n",
    "                files_keypoints.append( file_keypoints )\n",
    "                timings['feature_matching'].append(t)\n",
    "                \n",
    "            if CONFIG.use_dkm:\n",
    "                file_keypoints = f'{feature_dir}/matches_dkm.h5'\n",
    "                t = detect_dkm(\n",
    "                    img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
    "                    resize_to=CONFIG.params_dkm[\"resize_to\"], \n",
    "                    detection_threshold=CONFIG.params_dkm[\"detection_threshold\"], \n",
    "                    num_features=CONFIG.params_dkm[\"num_features\"], \n",
    "                    min_matches=CONFIG.params_dkm[\"min_matches\"]\n",
    "                )\n",
    "                gc.collect()\n",
    "                files_keypoints.append(file_keypoints)\n",
    "                timings['feature_matching'].append(t)\n",
    "                \n",
    "            #############################################################\n",
    "            # merge keypoints\n",
    "            #############################################################\n",
    "            keypoints_merger(\n",
    "                img_fnames,\n",
    "                index_pairs,\n",
    "                files_keypoints,\n",
    "                feature_dir = feature_dir,\n",
    "            )\n",
    "            \n",
    "            #############################################################\n",
    "            # regist keypoints from h5 into colmap db\n",
    "            #############################################################\n",
    "            database_path = f'{feature_dir}/colmap.db'\n",
    "            if os.path.isfile(database_path):\n",
    "                os.remove(database_path)\n",
    "            gc.collect()\n",
    "            import_into_colmap(img_dir, feature_dir=feature_dir,database_path=database_path)\n",
    "            output_path = f'{feature_dir}/colmap_rec'\n",
    "\n",
    "            #############################################################\n",
    "            # Calculate fundamental matrix with colmap api\n",
    "            #############################################################\n",
    "            t=time()\n",
    "            options = pycolmap.SiftMatchingOptions()\n",
    "            options.confidence = 0.9999\n",
    "            options.max_num_trials = 20000\n",
    "            pycolmap.match_exhaustive(database_path, sift_options=options)\n",
    "            t=time() - t \n",
    "            timings['RANSAC'].append(t)\n",
    "            print(f'RANSAC in  {t:.4f} sec')\n",
    "\n",
    "            #############################################################\n",
    "            # Execute bundle adjustmnet with colmap api\n",
    "            # --> Bundle adjustment Calcs Camera matrix, R and t\n",
    "            #############################################################\n",
    "            t=time()\n",
    "            # By default colmap does not generate a reconstruction if less than 10 images are registered. Lower it to 3.\n",
    "            mapper_options = pycolmap.IncrementalMapperOptions()\n",
    "            mapper_options.min_model_size = 3\n",
    "            os.makedirs(output_path, exist_ok=True)\n",
    "            maps = pycolmap.incremental_mapping(database_path=database_path, image_path=img_dir, output_path=output_path, options=mapper_options)\n",
    "            print(maps)\n",
    "            clear_output(wait=False)\n",
    "            t=time() - t\n",
    "            timings['Reconstruction'].append(t)\n",
    "            print(f'Reconstruction done in  {t:.4f} sec')\n",
    "\n",
    "            #############################################################\n",
    "            # Extract R,t from maps \n",
    "            #############################################################            \n",
    "            imgs_registered  = 0\n",
    "            best_idx = None\n",
    "            list_num_images = []            \n",
    "            print (\"Looking for the best reconstruction\")\n",
    "            if isinstance(maps, dict):\n",
    "                for idx1, rec in maps.items():\n",
    "                    print (idx1, rec.summary())\n",
    "                    list_num_images.append( len(rec.images) )\n",
    "                    if len(rec.images) > imgs_registered:\n",
    "                        imgs_registered = len(rec.images)\n",
    "                        best_idx = idx1\n",
    "            list_num_images = np.array(list_num_images)\n",
    "            print(f\"list_num_images = {list_num_images}\")\n",
    "            if best_idx is not None:\n",
    "                print (maps[best_idx].summary())\n",
    "                for k, im in maps[best_idx].images.items():\n",
    "                    key1 = f'test/{dataset}/images/{im.name}'\n",
    "                    out_results[dataset][scene][key1] = {}\n",
    "                    out_results[dataset][scene][key1][\"R\"] = deepcopy(im.rotmat())\n",
    "                    out_results[dataset][scene][key1][\"t\"] = deepcopy(np.array(im.tvec))\n",
    "                \n",
    "            print(f'Registered: {dataset} / {scene} -> {len(out_results[dataset][scene])} images')\n",
    "            print(f'Total: {dataset} / {scene} -> {len(data_dict[dataset][scene])} images')\n",
    "            create_submission(out_results, data_dict)\n",
    "            gc.collect()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebcdac",
   "metadata": {
    "papermill": {
     "duration": 0.013395,
     "end_time": "2024-05-25T05:45:53.920229",
     "exception": false,
     "start_time": "2024-05-25T05:45:53.906834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a128b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:45:53.948990Z",
     "iopub.status.busy": "2024-05-25T05:45:53.948375Z",
     "iopub.status.idle": "2024-05-25T05:45:55.021546Z",
     "shell.execute_reply": "2024-05-25T05:45:55.020180Z"
    },
    "papermill": {
     "duration": 1.090028,
     "end_time": "2024-05-25T05:45:55.023883",
     "exception": false,
     "start_time": "2024-05-25T05:45:53.933855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path,dataset,scene,rotation_matrix,translation_vector\r\n",
      "test/church/images/00046.png,church,church,1.0;0.0;0.0;0.0;1.0;0.0;0.0;0.0;1.0,0.0;0.0;0.0\r\n",
      "test/church/images/00090.png,church,church,0.9995848835757978;-0.0035332752743171916;-0.028593294539011264;-0.0017573865069070572;0.9831260578396469;-0.18292092824316378;0.028757122933702764;0.1828952442315306;0.9827117367356842,-0.1306330827363206;-0.002626870897479392;-0.8818020243011213\r\n",
      "test/church/images/00092.png,church,church,0.9478126755832507;-0.12427587433233046;-0.29360967126893894;0.14236114374630995;0.9889668245879749;0.040962478143052435;0.28527957647711494;-0.08062336462411118;0.9550473476858231,0.08026978491400699;-0.17767629437312435;-0.9601043232769088\r\n",
      "test/church/images/00087.png,church,church,0.8934444761978398;-0.16426585750377412;-0.4180594407618578;0.18144126137342506;0.983400843706596;0.0013598780738454871;0.41089662522681786;-0.07706820781427995;0.9084186560840255,0.7965018502350162;-0.11857231283712075;-1.0038098770967483\r\n",
      "test/church/images/00050.png,church,church,0.9240999486014865;0.17607316521585484;0.33917182295350007;-0.20058059008331539;0.9789278783573607;0.038309735793728185;-0.3252794366026834;-0.10343330926556757;0.9399440614514325,-2.990881033228072;0.309925382857683;0.6546227651324001\r\n",
      "test/church/images/00068.png,church,church,0.575332315016767;-0.2244821476378939;-0.7865115973012264;0.5231292763170267;0.8401937019560719;0.142864633319011;0.6287515308589489;-0.4936418829325874;0.6008237710487977,4.7153730785190415;0.2518530609034588;0.3615095733526549\r\n",
      "test/church/images/00083.png,church,church,0.9363236315971666;-0.14797624382112293;-0.3184353751976767;0.17572766760133343;0.9826029152112692;0.06009407506327505;0.3040030324718634;-0.11222540836596165;0.9460378501756704,1.350758112886094;-0.16345179809189106;-0.906726831673531\r\n",
      "test/church/images/00096.png,church,church,0.9426995168959925;0.09442506829401937;0.3200023864313078;-0.01213368152421719;0.9681844348760904;-0.2499433412522415;-0.33342224673337434;0.2317386600059113;0.913852722730492,-1.2048193050071947;0.01923844755049353;-1.236524702669991\r\n",
      "test/church/images/00069.png,church,church,0.5898071547101432;-0.22029988942098133;-0.7769140743826364;0.3446166624187966;0.938732407295433;-0.0045632747726397915;0.7303197082347255;-0.2650460831901215;0.6295901028046111,4.730146422712544;0.09729339659885418;0.43340442055220263\r\n",
      "test/church/images/00081.png,church,church,0.8910164040377399;-0.13896896379370904;-0.43217750385432824;0.16236678272978727;0.9865750701950242;0.017511674267790628;0.4239419719745064;-0.08577445990378453;0.9016185149089281,1.4494995705211493;-0.09927340560400581;-0.6902088160463982\r\n",
      "test/church/images/00042.png,church,church,0.7309259278439002;0.2056733251573325;0.6507271097197809;-0.25420314362815044;0.9669422480360995;-0.02008608305419629;-0.6333467058216213;-0.1507354380416906;0.7590459656327014,-4.92838823961517;2.390413834651318;6.4259548750595075\r\n",
      "test/church/images/00018.png,church,church,0.9844078465931445;-0.06169676379056601;-0.1647261391025093;0.08378952773564546;0.987870950234898;0.13072987693651822;0.15466255722599972;-0.14249384204158017;0.9776374575334885,0.1698004583123975;1.0047054799928872;2.4109987936098807\r\n",
      "test/church/images/00030.png,church,church,0.947681428155798;0.07959515905780801;0.3091351183271634;-0.15586610562105838;0.9605046437784935;0.23051374448929154;-0.27857793855061846;-0.26663728159151256;0.922658600034908,-2.885409239656989;0.0633020517755815;0.42787079844498527\r\n",
      "test/church/images/00024.png,church,church,0.8126640225522642;0.21684682626302274;0.5408832040180462;-0.2285421907501163;0.9724239236611097;-0.046477733794470746;-0.5360463165588496;-0.08584385028169848;0.8398125861598544,-0.31438335517859145;0.467652603465149;1.7494157329178515\r\n",
      "test/church/images/00032.png,church,church,0.9746326950862501;0.08542613097634666;0.20686586430661952;-0.10550952879702619;0.9905111903628608;0.0880643009339082;-0.19737996099387128;-0.10765666682728249;0.9743978618027122,-1.2131333263463482;0.4018190860066052;1.2575113844492816\r\n",
      "test/church/images/00026.png,church,church,0.9652864988647311;0.14233271852246077;0.21900541625146072;-0.18386010544807313;0.9658270243202106;0.18268448406307175;-0.18551937023958723;-0.216609224943845;0.958469095451248,-2.234097917541221;0.445908718965158;0.7141892866970672\r\n",
      "test/church/images/00037.png,church,church,-0.7831984744896918;0.2018898835179106;0.5880821579423611;-0.08607453904643281;0.9015054803434699;-0.4241214951386379;-0.6157851275282343;-0.38279020865718866;-0.6886801382871603,-0.6870090171220383;0.4445556688219821;3.7160871454624442\r\n",
      "test/church/images/00008.png,church,church,0.9999755885334533;0.0007918172467634388;0.00694228799615012;-0.0007042712912723909;0.9999203194035622;-0.012603921843079175;-0.006951714833194153;0.012598724908731313;0.9998964675362905,-0.914176219343297;1.242948245632168;4.675130752206898\r\n",
      "test/church/images/00035.png,church,church,-0.46362997940006156;0.2209482236378131;0.8580379506017164;-0.3482174438903538;0.8450473703857329;-0.4057579987808329;-0.8147342229046026;-0.48690535453561506;-0.31485126925674,-0.8692107069949249;1.2172619958736801;3.565089698074021\r\n",
      "test/church/images/00021.png,church,church,0.9705302521395787;0.13864399087135018;0.19710117573761646;-0.15164273239587897;0.9870460557319138;0.052388601580719604;-0.18728457329261702;-0.08073368354866821;0.9789824109488718,-1.9248514824340595;0.6355416256574855;1.6430448815590755\r\n",
      "test/church/images/00010.png,church,church,0.9970741629242665;-0.018819589826821977;-0.07408735835230783;0.012941688820912768;0.9967880203205165;-0.07903262134061065;0.07533675277934242;0.07784256922954086;0.9941151382492918,-0.6406012352736122;0.8492075149203311;4.314015192162323\r\n",
      "test/church/images/00039.png,church,church,0.5835711313324248;0.25393658142242914;0.7713371165002264;-0.33395399249504676;0.9408591318199638;-0.05708611886967163;-0.7402158236433561;-0.224277298642716;0.633861363187183,-2.168484377229601;0.7094049107446426;1.820626605136715\r\n",
      "test/church/images/00011.png,church,church,0.9994812061907413;0.012629232838341898;0.02962804329374006;-0.012575926242210324;0.9999189499344338;-0.0019848529340630557;-0.02965070910874265;0.0016112231174854855;0.999559022474118,0.14124981816796092;1.0085995829574872;3.729901645299605\r\n",
      "test/church/images/00013.png,church,church,0.9940774862718669;0.02129680924880187;0.10656639809633432;-0.007747321329075488;0.9920027432660239;-0.12597831704268425;-0.10839709543908597;0.12440660460161736;0.9862925866252197,0.4423763994352998;0.5326466179321495;3.8206402175153973\r\n",
      "test/church/images/00006.png,church,church,0.9710037780731419;-0.0695026862402236;0.2287379277100274;0.08760839813826277;0.9936949670622156;-0.06996485554097769;-0.22243298213918802;0.08797550250277218;0.9709705862774899,0.00892769015261323;0.9108582096198391;4.788646965421826\r\n",
      "test/church/images/00012.png,church,church,0.9990521033301427;0.006631962836613377;-0.043022225657810914;-0.009594149515445023;0.9975694343790822;-0.06901576550088699;0.042459947323249356;0.0693631073520493;0.9966874696773181,0.08185093418297207;0.425118579358703;2.3575504901465796\r\n",
      "test/church/images/00029.png,church,church,0.9980810330606089;-0.005354140652255528;0.061689420669540765;0.0050386762344490025;0.9999734286378212;0.005268183759565869;-0.0617159880944322;-0.0049472412712560825;0.9980814904692562,-1.0657911864454308;0.30047797446136965;1.5626414354123705\r\n",
      "test/church/images/00001.png,church,church,0.946330776656207;0.10854453046062155;0.3044275711238115;-0.1224942077310051;0.9921006964936294;0.027043984344190097;-0.29908732876137284;-0.06288316884460121;0.9521514988962879,1.0021748025629134;1.491847578646425;4.605666134052797\r\n",
      "test/church/images/00098.png,church,church,1.0;0.0;0.0;0.0;1.0;0.0;0.0;0.0;1.0,0.0;0.0;0.0\r\n",
      "test/church/images/00072.png,church,church,0.7515323210823999;-0.18944944474182965;-0.6319082831040539;0.3245396197606759;0.9401236410920788;0.10412288252525467;0.5743458936686991;-0.2833309855042059;0.7680171528547516,3.3012569204897417;0.2295911096178531;0.05939944276611719\r\n",
      "test/church/images/00066.png,church,church,0.5466931546102023;-0.25092098475178304;-0.798852460792067;0.34655535666639714;0.9363004102981467;-0.05692913525909565;0.7622506014875762;-0.24572383092959788;0.5988270363344583,4.711099201319972;0.28131112705468636;0.610680737509326\r\n",
      "test/church/images/00104.png,church,church,1.0;0.0;0.0;0.0;1.0;0.0;0.0;0.0;1.0,0.0;0.0;0.0\r\n",
      "test/church/images/00058.png,church,church,0.995523568862743;0.030679540909944514;-0.08939569121799135;-0.06648215248684908;0.8996010418990468;-0.43162262314997446;0.06717847303640329;0.43563371217538316;0.8976136817009824,0.43744185152485826;0.10639949438375655;0.5850429984083192\r\n",
      "test/church/images/00059.png,church,church,-0.1489173904583594;-0.28869013028468477;-0.9457703841288777;0.5664057910322808;0.7590874576101788;-0.32089049780884976;0.8105603559909461;-0.5834759981139985;0.05047443829013076,6.030138926287101;2.546010399684209;3.953109514477047\r\n",
      "test/church/images/00111.png,church,church,0.8669706004772307;0.18951534333887948;0.4609185530517258;-0.27036363550844544;0.9557990934455312;0.1155491132088746;-0.41864720529678257;-0.2247932997396664;0.8798877711897956,-3.7052557578926013;0.8243172527732262;1.1219734000035857\r\n",
      "test/church/images/00061.png,church,church,0.9922954735203986;-0.01711902571280864;-0.12270546927326473;0.03313430760641252;0.9910004024347234;0.1296931765115648;0.11938094860726964;-0.1327597127627974;0.9839324406567597,-0.4028743399178022;1.0003181823192588;1.4407320106036827\r\n",
      "test/church/images/00060.png,church,church,0.9765501681166546;-0.0486860222400154;-0.2097127568598973;0.03631863539134519;0.9973884529099997;-0.062427804102882845;0.21220444357893217;0.05334740143851538;0.9757680712572603,0.34676282788979806;0.3526194200850124;0.5482903916339379\r\n",
      "test/church/images/00074.png,church,church,0.8580284408565106;-0.17307850683360865;-0.4835607771041753;0.15389299879526586;0.9848882189558229;-0.0794489841585613;0.49000422406663563;-0.006247130083126669;0.8716976733722414,3.331385988464915;0.06888675614154768;-0.19390832756686976\r\n",
      "test/church/images/00102.png,church,church,1.0;0.0;0.0;0.0;1.0;0.0;0.0;0.0;1.0,0.0;0.0;0.0\r\n",
      "test/church/images/00076.png,church,church,0.4666527382270119;-0.26072332818859845;-0.8451381946424457;0.30720941982133376;0.9438479600789265;-0.12154587869561292;0.8293718070191869;-0.20291469733143916;0.520545897427517,4.537917905474685;1.0599925617863617;2.7738691007125618\r\n",
      "test/church/images/00063.png,church,church,0.886681176265902;-0.16785504858762024;-0.4308377586973593;0.39111906805442254;0.7692633793950481;0.5052323502369482;0.24662190952945837;-0.6164888772600507;0.7477426682721039,0.15071403287330826;0.05098994432683734;-0.05100957615039819\r\n"
     ]
    }
   ],
   "source": [
    "!cat submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a45689fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T05:45:55.052282Z",
     "iopub.status.busy": "2024-05-25T05:45:55.051873Z",
     "iopub.status.idle": "2024-05-25T05:45:55.066513Z",
     "shell.execute_reply": "2024-05-25T05:45:55.065693Z"
    },
    "papermill": {
     "duration": 0.031382,
     "end_time": "2024-05-25T05:45:55.068611",
     "exception": false,
     "start_time": "2024-05-25T05:45:55.037229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "submission = pd.read_csv('/kaggle/working/submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8143495,
     "sourceId": 71885,
     "sourceType": "competition"
    },
    {
     "datasetId": 2058261,
     "sourceId": 3414836,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3117886,
     "sourceId": 5373920,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4628051,
     "sourceId": 7884485,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 103280447,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 170475544,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 170565695,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 174129945,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 2663,
     "sourceId": 3736,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 2742,
     "sourceId": 3840,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 2747,
     "sourceId": 3846,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 3326,
     "sourceId": 4534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 14317,
     "sourceId": 17191,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 14611,
     "sourceId": 17555,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 2668,
     "sourceId": 3741,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2472.642217,
   "end_time": "2024-05-25T05:45:57.977266",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-25T05:04:45.335049",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
